{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats vs Dogs  Solve\n",
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition\n",
    "\n",
    "Using VGG16 model to solve above kaggle competition\n",
    "\n",
    "Usage Notes:\n",
    "* Cells should be convereted to raw if they don't need to be run\n",
    "\n",
    "Things to work on:\n",
    "* Loop over training and learning rate array\n",
    "* Data augmentation\n",
    "* Save VGG16 architecture to file and just load that shit!\n",
    "\n",
    "References\n",
    "* https://github.com/fastai/courses/blob/master/deeplearning1/nbs/dogscats-ensemble.ipynb\n",
    "* https://github.com/fastai/courses/blob/master/deeplearning1/nbs/dogs_cats_redux.ipynb\n",
    "\n",
    "\n",
    "Process\n",
    "1. Start as VGG16 model\n",
    "1. Train the last layer, precomputing the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "ERROR (theano.gpuarray): pygpu was configured but could not be imported or is too old (version 0.6 or higher required)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 21, in <module>\n",
      "    import pygpu\n",
      "ImportError: No module named pygpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "from vgg16 import VGG_16\n",
    "from utils import *\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "#Jupyter Specific\n",
    "%matplotlib inline\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dir_case = './data/dogscats/'\n",
    "dir_data = dir_case + 'population/'\n",
    "ensambles_nb = 1\n",
    "\n",
    "# Sane Defaults, but feel free to change\n",
    "dir_model =  dir_case + 'model/'\n",
    "dir_submissions =  dir_case + 'submissions/'\n",
    "fname_submission =  'Kaggle_CatsDogs'\n",
    "fname_stats = dir_case + 'stats.csv'\n",
    "batch_size = 24\n",
    "\n",
    "# Constants\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "generators = {}\n",
    "\n",
    "generators['train'] = image.ImageDataGenerator().flow_from_directory(dir_data+'train', \n",
    "                                                                     batch_size=batch_size,\n",
    "                                                                     shuffle=False,\n",
    "                                                                     class_mode='categorical',\n",
    "                                                                     target_size=IMAGE_SIZE)\n",
    "\n",
    "generators['valid'] = image.ImageDataGenerator().flow_from_directory(dir_data+'valid', \n",
    "                                                                     batch_size=batch_size,\n",
    "                                                                     shuffle=False,\n",
    "                                                                     class_mode='categorical',\n",
    "                                                                     target_size=IMAGE_SIZE)\n",
    "\n",
    "generators['test']  = image.ImageDataGenerator().flow_from_directory(dir_data+'test', \n",
    "                                                                     batch_size=batch_size,\n",
    "                                                                     shuffle=False,\n",
    "                                                                     class_mode=None,\n",
    "                                                                     target_size=IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Data Augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras ImageDataGenerator Arugments:\n",
    "\n",
    "* featurewise_center: Boolean. Set input mean to 0 over the dataset, feature-wise.\n",
    "* samplewise_center: Boolean. Set each sample mean to 0.\n",
    "* featurewise_std_normalization: Boolean. Divide inputs by std of the dataset, feature-wise.\n",
    "* samplewise_std_normalization: Boolean. Divide each input by its std.\n",
    "* zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n",
    "* zca_whitening: Boolean. Apply ZCA whitening.\n",
    "* rotation_range: Int. Degree range for random rotations.\n",
    "* width_shift_range: Float (fraction of total width). Range for random horizontal shifts.\n",
    "* height_shift_range: Float (fraction of total height). Range for random vertical shifts.\n",
    "* shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction as radians)\n",
    "* zoom_range: Float or [lower, upper]. Range for random zoom. If a float, [lower, upper] = [1-zoom_range, 1+zoom_range].\n",
    "* channel_shift_range: Float. Range for random channel shifts.\n",
    "* fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}. Points outside the boundaries of the input are filled according to the given mode:\n",
    "        \"constant\": kkkkkkkk|abcd|kkkkkkkk (cval=k)\n",
    "        \"nearest\": aaaaaaaa|abcd|dddddddd\n",
    "        \"reflect\": abcddcba|abcd|dcbaabcd\n",
    "        \"wrap\": abcdabcd|abcd|abcdabcd\n",
    "* cval: Float or Int. Value used for points outside the boundaries when fill_mode = \"constant\".\n",
    "* horizontal_flip: Boolean. Randomly flip inputs horizontally.\n",
    "* vertical_flip: Boolean. Randomly flip inputs vertically.\n",
    "* rescale: rescaling factor. Defaults to None. If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided (before applying any other transformation).\n",
    "    preprocessing_function: function that will be implied on each input. The function will run before any other modification on it. The function should take one argument: one image (Numpy tensor with rank 3), and should output a Numpy tensor with the same shape.\n",
    "* data_format: One of {\"channels_first\", \"channels_last\"}. \"channels_last\" mode means that the images should have shape (samples, height, width, channels), \"channels_first\" mode means that the images should have shape (samples, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"channels_last\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a augmented data generator\n",
    "datagen = image.ImageDataGenerator(\n",
    "                                    rotation_range=10,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    zoom_range=0.1,\n",
    "                                    channel_shift_range=10,\n",
    "                                    shear_range=0.05,\n",
    "                                    horizontal_flip=True,\n",
    "                                    dim_ordering='tf'\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test augmentation on one image\n",
    "img = np.expand_dims(ndimage.imread(dir_data+'test/unknown/00005.jpg'),0)\n",
    "gen_aug = datagen.flow(img)\n",
    "\n",
    "n = 8\n",
    "(imgs) = [next(gen_aug)[0] for i in range(n)] \n",
    "images = imgs[0]\n",
    "\n",
    "\n",
    "plots(img) #Use utily.py plot function for ease\n",
    "plots(imgs[:n/2]) #Use utily.py plot function for ease\n",
    "plots(imgs[n/2:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking State\n",
    "\n",
    "We track data about the training process in a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load stats if found, otherwise create a blank one\n",
    "if os.path.exists(fname_stats):\n",
    "    stats = pd.read_csv(fname_stats)\n",
    "else:\n",
    "    stats = pd.DataFrame(columns=['model','epoch','learning_rate','acc','loss','val_acc','val_loss'])\n",
    "\n",
    "    \n",
    "display(stats.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "latests_models = []\n",
    "for m in range(0, ensambles_nb):\n",
    "    ind = stats.query('model==@m')['epoch'].idxmax()\n",
    "    latests_models.append(ind)\n",
    "\n",
    "stats_sum = stats.iloc[latests_models]\n",
    "display(stats_sum.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16 = VGG_16(generators, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VGG16.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layers, fc_layers = split_at(VGG16.model, Flatten)\n",
    "conv_model = Sequential(conv_layers)\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precompute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_trn = conv_model.predict_generator(generators['train'], generators['train'].nb_sample, )\n",
    "features_val = conv_model.predict_generator(generators['valid'], generators['valid'].nb_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(dir_model + 'features_trn_conv.bc', features_trn)\n",
    "save_array(dir_model + 'features_val_conv.bc', features_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "features_trn = load_array(dir_model + 'features_trn_conv.bc')\n",
    "features_val = load_array(dir_model +  'features_val_conv.bc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_trn = to_categorical(generators['train'].classes)\n",
    "labels_val = to_categorical(generators['valid'].classes)\n",
    "labels_val[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_output = features_trn.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fc_layers(p, in_shape):\n",
    "    return [\n",
    "        Dense(4096, activation='relu', input_shape=in_shape),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(p),\n",
    "        Dense(2, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model = Sequential(get_fc_layers(0.5, conv_output))\n",
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Weights from VGG16 model\n",
    "for l1,l2 in zip(fc_model.layers, fc_layers): \n",
    "    l1.set_weights(l2.get_weights())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "display(fc_model.predict(features_val)[:n])\n",
    "display(VGG16.predict_gen(generators['valid'])[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model.compile(optimizer=Adam(lr=0.01),loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.save(dir_model+'fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model = load_model(dir_model+'fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 411041792 bytes of device memory (out of memory).\nApply node that caused the error: GpuDot22Scalar(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{Switch(i0, (i1 * i2), i3)}(i1, i2, i3, i4)) + (i0 * Composite{Switch(i0, (i1 * i2), i3)}(i1, i2, i3, i4) * sgn(i5)))}}[(0, 2)].0, HostFromGpu.0)\nToposort index: 112\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(float32, scalar)]\nInputs shapes: [(25088, 1), (1, 4096), ()]\nInputs strides: [(1, 0), (0, 1), ()]\nInputs values: ['not shown', 'not shown', array(0.10000002384185791, dtype=float32)]\nOutputs clients: [[GpuElemwise{Composite{((i0 * i1) + i2)}}[(0, 1)](GpuDimShuffle{x,x}.0, <CudaNdarrayType(float32, matrix)>, GpuDot22Scalar.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bf4cbd2a27fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m fc_model.fit(features_trn[:2000], labels_trn[:2000], nb_epoch = 1, batch_size=1,\n\u001b[0;32m----> 2\u001b[0;31m                                  validation_data = (features_val, labels_val))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Error allocating 411041792 bytes of device memory (out of memory).\nApply node that caused the error: GpuDot22Scalar(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{Switch(i0, (i1 * i2), i3)}(i1, i2, i3, i4)) + (i0 * Composite{Switch(i0, (i1 * i2), i3)}(i1, i2, i3, i4) * sgn(i5)))}}[(0, 2)].0, HostFromGpu.0)\nToposort index: 112\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(float32, scalar)]\nInputs shapes: [(25088, 1), (1, 4096), ()]\nInputs strides: [(1, 0), (0, 1), ()]\nInputs values: ['not shown', 'not shown', array(0.10000002384185791, dtype=float32)]\nOutputs clients: [[GpuElemwise{Composite{((i0 * i1) + i2)}}[(0, 1)](GpuDimShuffle{x,x}.0, <CudaNdarrayType(float32, matrix)>, GpuDot22Scalar.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "fc_model.fit(features_trn[:2000], labels_trn[:2000], nb_epoch = 1, batch_size=1,\n",
    "                                 validation_data = (features_val, labels_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for m in range(0, ensambles_nb):\n",
    "    models.append(VGG_16(generators, batch_size=24))\n",
    "    fname_model =  '{}weights_model{:02d}.h5'.format(dir_model, m)\n",
    "    if os.path.exists(fname_model):\n",
    "        models[m].model.load_weights(fname_model)\n",
    "        print( 'Loaded Weights from: {}'.format(fname_model) )\n",
    "    else:\n",
    "        print('Created new weights: {}'.format(fname_model))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = np.array([\n",
    "#    [0.030, 2],\n",
    "#    [0.010, 2],\n",
    "    [0.001, 1],\n",
    "])\n",
    "m=0\n",
    "for model in models:\n",
    "    print('Training model {:02d}'.format(m))\n",
    "    for step in training:\n",
    "        model.lr = step[0]\n",
    "        for epoch in range(0,int(step[1])):\n",
    "            \n",
    "            epochs_current = stats.query('model==@m')['epoch'].max() + 1\n",
    "            \n",
    "            # if we didn't find anything in the dataframe, it must be a new model\n",
    "            if np.isnan(epochs_current):\n",
    "                epochs_current = 0\n",
    "            \n",
    "            print('Training epoch {} at {}'.format(epochs_current, model.lr))\n",
    "\n",
    "            # Train single epoch\n",
    "            hist = model.fit_gen(nb_epoch=1)\n",
    "            \n",
    "            # Update stats\n",
    "            stats_slug = {}\n",
    "            \n",
    "            # Convert results array to float\n",
    "            for key in hist.history:\n",
    "                hist.history[key] = float(hist.history[key][0])\n",
    "\n",
    "            # Add learning parameters\n",
    "            stats_slug.update({'model': m,\n",
    "                              'epoch': epochs_current,\n",
    "                              'learning_rate': model.lr})\n",
    "            \n",
    "            ## Add accuracy\n",
    "            stats_slug.update(hist.history)\n",
    "\n",
    "            stats = stats.append(stats_slug, ignore_index=True)\n",
    "            \n",
    "            #['model','epochs','learning_rate','loss', 'acc','loss_val','acc_val']\n",
    "            \n",
    "            model.model.save_weights(fname_model)\n",
    "            \n",
    "    # Go to next model\n",
    "    m += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.to_csv(fname_stats, index=False)\n",
    "display(stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = model.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for validation set\n",
    "preds_valid = pred_ensamble(models, generators[1])\n",
    "fnames_valid = np.array(generators[1].filenames)\n",
    "#strip category folder\n",
    "#fnames = np.array([f[f.find('/')+1:] for f in fnames])\n",
    "\n",
    "display(preds_valid[:10])\n",
    "display(fnames_valid[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precomputing up to the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.model.pop()\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict_gen(model.gen_valid)\n",
    "display(preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(imgs, labels) = next(model.gen_train)\n",
    "\n",
    "n = 4\n",
    "imgs = imgs[:4]\n",
    "labels = labels[:4]\n",
    "plots(imgs, titles=labels) #Use utily.py plot function for ease\n",
    "\n",
    "\n",
    "print(model.predict(imgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert predictions into a label\n",
    "labels_pred = np.round(preds_valid[:,1]) #Get probality it is dog\n",
    "\n",
    "labels_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get labels\n",
    "labels_actual = generators[1].classes\n",
    "labels_actual[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_actual, labels_pred)\n",
    "\n",
    "plot_confusion_matrix(cm, classes, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "valid_path = dir_data + 'valid/'\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(valid_path + fnames_valid[i]) for i in idx], titles=titles)\n",
    "\n",
    "n_view = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. A few correct predictions at random\n",
    "correct = np.where(labels_actual==labels_pred)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "idx = permutation(correct)[:n_view]\n",
    "plots_idx(idx, preds_valid[idx])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "imgs = next(batches_test)\n",
    "\n",
    "n = 4\n",
    "imgs = imgs[:4]\n",
    "labels = labels[:4]\n",
    "plots(imgs, titles=labels) #Use utily.py plot function for ease\n",
    "\n",
    "\n",
    "print(model.predict(imgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. A few incorrect predictions at random\n",
    "correct = np.where(labels_actual!=labels_pred)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "idx = permutation(correct)[:n_view]\n",
    "plots_idx(idx, preds_valid[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((labels_pred==0) & (labels_pred==labels_actual))[0]\n",
    "print \"Found %d confident correct cats labels\" % len(correct_cats)\n",
    "most_correct_cats = np.argsort(preds_valid[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], preds_valid[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Submission\n",
    "\n",
    "Format Kaggle requires for submissions:\n",
    "```\n",
    "    imageId,isDog\n",
    "    1242, .3984\n",
    "    3947, .1000\n",
    "    4539, .9082\n",
    "    2345, .0000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_ensamble(models, generator):\n",
    "    pred_test = 0\n",
    "    \n",
    "    for model in models:\n",
    "        pred_test += model.predict_gen(generator)\n",
    "        \n",
    "    pred_test /= len(models)\n",
    "    \n",
    "    return pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on test data and get predictions\n",
    "pred_test = pred_ensamble(models, generators[2])\n",
    "\n",
    "\n",
    "display(pred_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = model.classes\n",
    "display(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab dog predictions\n",
    "isDog = pred_test[:,1]\n",
    "\n",
    "#Get imageids, then strip category folder and extension\n",
    "imageId = np.array(model.gen_test.filenames)\n",
    "imageId = np.array([f[f.find('/')+1:] for f in imageId]) #strip category folder\n",
    "imageId = np.array([f[:f.find('.')] for f in imageId]) #strip filename\n",
    "\n",
    "display(isDog[:5])\n",
    "display(imageId[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Evaluation\n",
    "\n",
    "Kaggle uses categorical log loss defined as:\n",
    "\n",
    "$$\\textrm{LogLoss} = - \\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)\\right]$$\n",
    "- $n$ is the number of images in the test set\n",
    "- $\\hat{y}_i$  is the predicted probability of the image being a dog\n",
    "- $y_i$ is 1 if the image is a dog, 0 if cat\n",
    "- $log()$ is the natural (base e) logarithm\n",
    "\n",
    "As shown in the plot below, there is a \"infinte\" penality for predicting the wrong label with high confidence, i.e. predicting 0 when it should be 1. A trick to improve kaggle score is to clip the confident predictions.\n",
    "\n",
    "The clipping amount is random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets plot the log loss for the case that the image is a dog, i.e. y_i = 1\n",
    "from sympy import symbols, log\n",
    "from sympy import plot\n",
    "import math\n",
    "\n",
    "y = symbols('y')\n",
    "loss = - ( 1*log(y) + (1-y)*log(1-y) )\n",
    "\n",
    "plot(loss, (y, 0, 1), xlabel='Prediction', ylabel='Log Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipping = 0.05\n",
    "\n",
    "isDog = isDog.clip(min=clipping, max=1-clipping)\n",
    "display(isdog[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compile results into a Pandas Dataframe\n",
    "subm = pd.DataFrame() \n",
    "subm.insert(0,\"imageId\",imageId) # insert id to the first column\n",
    "subm.insert(1,\"isDog\",isDog) # insert predictions\n",
    "display(subm.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "fname_submission_timestapped = '%s_%s.csv' % ( dir_submissions+fname_submission, datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "\n",
    "display(fname_submission_timestapped)\n",
    "\n",
    "subm.to_csv(fname_submission_timestapped, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
